{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Translation Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims to translate sentences from German to English. There are in total 200,000 pairs of sentences from IWSLT 2016. The current model script is named as `transformer.py`, which contains a bert tokenizer and a transformer model. This notebook aims to provide an example that highlights the ease of integrating with users' codes and the use of Azure Datastore. \n",
    "\n",
    "Table of Content:\n",
    "1. [Set up workspace](#Set-up-workspace)\n",
    "2. [Set up datastore](#Set-up-datastore)\n",
    "3. [Specify compute target](#Specify-compute-target)\n",
    "4. [Create estimator and submit an experiment](#Create-estimator-and-submit-an-experiment)\n",
    "5. [Cancel runs](#Cancel-runs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T12:45:30.469377Z",
     "start_time": "2019-04-12T12:45:16.596652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.0.23\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import simplejson as json\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Experiment, Run, Datastore, ScriptRunConfig\n",
    "from azureml.data.data_reference import DataReference\n",
    "\n",
    "# import compute target \n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "\n",
    "from azureml.train.dnn import PyTorch\n",
    "\n",
    "# check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T12:46:30.079394Z",
     "start_time": "2019-04-12T12:45:41.924407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /Users/chengyineng/Documents/Projects/microsoft-azure-ml-notebooks/machine-translation/config.json\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T13:16:51.375785Z",
     "start_time": "2019-04-12T13:16:51.371015Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chengyineng/Documents/Projects/microsoft-azure-ml-notebooks/machine-translation/config.json\n"
     ]
    }
   ],
   "source": [
    "# load config file\n",
    "\n",
    "config_path = os.path.join(os.getcwd(), 'config.json')\n",
    "print(config_path)\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up datastore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we register a datastore specifically for this machine translation project. To read more about how to use a datastore to access your data, you can go to this [web page](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-access-data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T13:18:47.981198Z",
     "start_time": "2019-04-12T13:18:46.009089Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AzureBlob amherstwstorageinnganzr azureml-blobstore-fe92660d-c6c1-4086-b2f7-71f9c508e6c7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_4b1e1205ec574e4e8b1a1e86d6fe3d00"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ws.get_default_datastore()\n",
    "print(ds.datastore_type, ds.account_name, ds.container_name)\n",
    "\n",
    "\n",
    "# #define default datastore for current workspace\n",
    "ds = Datastore.register_azure_blob_container(workspace=ws, \n",
    "                                             datastore_name='machine_translation', \n",
    "                                             container_name=config[\"container_name\"],\n",
    "                                             account_name=config[\"account_name\"], \n",
    "                                             account_key=config[\"account_key\"],\n",
    "                                             create_if_not_exists=True)\n",
    "\n",
    "#get named datastore from current workspace\n",
    "ds = Datastore.get(ws, datastore_name='machine_translation')\n",
    "\n",
    "ds.path('./machine_translation').as_download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can locate your datastore on the portal itself.\n",
    "<br>\n",
    "<img src=\"images/datastore.png\" width=\"1500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your experiment name within the workspace you desire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T12:46:31.624372Z",
     "start_time": "2019-04-12T12:46:31.61571Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment_name = 'machine_translation-transformer'\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<img src=\"images/experiment_name.png\" width=\"1500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify compute target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T02:58:51.863411Z",
     "start_time": "2019-04-12T02:58:50.51728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found compute target. just use it. nv12\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "import os\n",
    "\n",
    "# choose a name for your cluster\n",
    "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"nv12\")\n",
    "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n",
    "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n",
    "\n",
    "# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6/STANDARD_D2_V2\n",
    "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_STANDARD_NC24\", \"STANDARD_NC24\")\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('found compute target. just use it. ' + compute_name)\n",
    "else:\n",
    "    print('creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n",
    "                                                                min_nodes = compute_min_nodes, \n",
    "                                                                max_nodes = compute_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "    \n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "     # For a more detailed view of current AmlCompute status, use get_status()\n",
    "    print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can go to the portal to view existing compute targets or create a new target.\n",
    "<br>\n",
    "<img src=\"images/compute_target.png\" width=\"1500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mount the datastore folder that you just created so that when the experiment is submitted, it knows where to find the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T02:59:01.498749Z",
     "start_time": "2019-04-12T02:59:01.485558Z"
    }
   },
   "outputs": [],
   "source": [
    "script_params = {\n",
    "    '--data-folder': ds.as_mount()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create estimator and submit an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T20:27:52.50884Z",
     "start_time": "2019-04-10T20:27:52.497699Z"
    }
   },
   "outputs": [],
   "source": [
    "pt_est = PyTorch(source_directory='./', \n",
    "                 script_params=script_params,\n",
    "                 compute_target=compute_target,\n",
    "                 entry_script='transformer.py',\n",
    "                 pip_packages=['torchtext','bert-embedding'], # specify the packages that you need the run to install\n",
    "                 use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T20:28:05.264712Z",
     "start_time": "2019-04-10T20:27:53.626915Z"
    }
   },
   "outputs": [],
   "source": [
    "run = exp.submit(pt_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T13:20:03.451056Z",
     "start_time": "2019-04-12T13:20:03.447848Z"
    }
   },
   "source": [
    "### To show widget of the experiment run details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can retrieve the logs for the experiment runs in the portal. \n",
    "<br>\n",
    "<img src=\"images/log_details.png\" width=\"1500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if you have to submit multiple experiment runs, you do not have to worry about the changes that you make to the scripts because Azure keeps track of the scripts. You can even download a snapshot of your experiment run on the portal.\n",
    "<br>\n",
    "<img src=\"images/snapshot.png\" width=\"1500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cancel runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To cancel the last run:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you realize that you have made mistakes in your submitted runs, you can immediately cancel it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T02:52:50.626457Z",
     "start_time": "2019-04-12T02:52:49.732282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did the run cancel? Canceled\n"
     ]
    }
   ],
   "source": [
    "local_script_run = exp.submit(pt_est)\n",
    "print(\"Did the run start?\",local_script_run.get_status())\n",
    "\n",
    "local_script_run.cancel()\n",
    "print(\"Did the run cancel?\",local_script_run.get_status())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To cancel a run based on experiment ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you submitted multiple experiments and you want to cancel a specific experiment, you can retrieve an experiment's `Run Id` to cancel it directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T12:53:59.50194Z",
     "start_time": "2019-04-12T12:53:52.977269Z"
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import get_run\n",
    "run_cpu_id = 'machine_translation_1554915123_b8da5e9d' #get from portal\n",
    "run=get_run(exp, run_cpu_id)\n",
    "run.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can also navigate to the experiment run on the portal to use the `cancel` button.\n",
    "<br>\n",
    "<img src=\"images/cancel_runs.png\" width=\"800\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language": "fsharp",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
