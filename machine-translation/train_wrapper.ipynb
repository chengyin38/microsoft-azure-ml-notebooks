{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Translation Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims to translate sentences from German to English. There are in total 200,000 pairs of sentences from IWSLT 2016. You can read more about the IWSLT 2016 data set [here](https://sites.google.com/site/iwsltevaluation2016/). The current model script is named as `transformer.py`, which contains a bert tokenizer and a transformer model. A transformer is a language model with attention mechanism that looks at an input sentence and decide which word of the sentence is important. If you are curious to learn more about what a transformer model is, feel free to check out this [blog post here](http://jalammar.github.io/illustrated-transformer/). The transformer model is implemented based on a tutorial linked [here](https://github.com/bentrevett/pytorch-seq2seq/blob/master/6%20-%20Attention%20is%20All%20You%20Need.ipynb). In this notebook, a transformer model will be used to generate translate German sentences to English.\n",
    "\n",
    "\n",
    "This notebook aims to provide an example that highlights the ease of integrating with users' codes and the use of Azure Datastore. \n",
    "\n",
    "Table of Content:\n",
    "1. [Set up workspace](#Set-up-workspace)\n",
    "2. [Set up datastore](#Set-up-datastore)\n",
    "3. [Specify compute target](#Specify-compute-target)\n",
    "4. [Create an experiment](#Create-an-experiment)\n",
    "5. [Create estimator and submit an experiment](#Create-estimator-and-submit-an-experiment)\n",
    "6. [Results](#Results)\n",
    "5. [Helpful to know: cancel runs](#Helpful-to-know:-cancel-runs)\n",
    "\n",
    "\n",
    "Tip: if you need to debug your SDK, you can run this line `from azureml._logging.debug_mode import debug_sdk` and call `debug_sdk()` just before the code block you want to debug."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T12:45:30.469377Z",
     "start_time": "2019-04-12T12:45:16.596652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.0.33\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import simplejson as json\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Experiment, Run, Datastore, ScriptRunConfig\n",
    "from azureml.data.data_reference import DataReference\n",
    "\n",
    "# import compute target \n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "\n",
    "from azureml.train.dnn import PyTorch\n",
    "\n",
    "# check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T12:46:30.079394Z",
     "start_time": "2019-04-12T12:45:41.924407Z"
    }
   },
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T13:16:51.375785Z",
     "start_time": "2019-04-12T13:16:51.371015Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chengyineng/Documents/Projects/microsoft-azure-ml-notebooks/machine-translation/config.json\n"
     ]
    }
   ],
   "source": [
    "# load config file\n",
    "\n",
    "config_path = os.path.join(os.getcwd(), 'config.json')\n",
    "print(config_path)\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook was validated with the AzureML SDK version 1.0.33. You are currently using  1.0.33\n"
     ]
    }
   ],
   "source": [
    "print(\"This notebook was validated with the AzureML SDK version 1.0.33. You are currently using \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up datastore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we register a datastore specifically for this machine translation project. To read more about how to use a datastore to access your data, you can go to this [web page](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-access-data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T13:18:47.981198Z",
     "start_time": "2019-04-12T13:18:46.009089Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AzureBlob amherstwstorageinnganzr azureml-blobstore-fe92660d-c6c1-4086-b2f7-71f9c508e6c7\n"
     ]
    }
   ],
   "source": [
    "ds = ws.get_default_datastore()\n",
    "print(ds.datastore_type, ds.account_name, ds.container_name)\n",
    "\n",
    "\n",
    "# #define default datastore for current workspace\n",
    "ds = Datastore.register_azure_blob_container(workspace=ws, \n",
    "                                             datastore_name='machine_translation', \n",
    "                                             container_name=config[\"container_name\"],\n",
    "                                             account_name=config[\"account_name\"], \n",
    "                                             account_key=config[\"account_key\"],\n",
    "                                             create_if_not_exists=True)\n",
    "\n",
    "#get named datastore from current workspace\n",
    "ds = Datastore.get(ws, datastore_name='machine_translation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your local training script, which is `transformer.py` in this notebook, you can specify your data folder as such to mount the datastore on Azure:\n",
    "\n",
    "```Python\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder mounting point')\n",
    "args = parser.parse_args()\n",
    "\n",
    "data_folder = os.path.join(args.data_folder, 'machine_translation')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount the datastore folder that you just created to find the data.\n",
    "script_params = {\n",
    "    '--data-folder': ds.as_mount()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, you can locate your datastore on the portal itself.\n",
    "<br>\n",
    "<img src=\"images/datastore.png\" width=\"1500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify compute target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify a compute target based on an existing cluster or you can create a new compute target. You can view your existing clusters here \n",
    "<br>\n",
    "<img src=\"images/compute_target.png\" width=\"2000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T02:58:51.863411Z",
     "start_time": "2019-04-12T02:58:50.51728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<azureml.core.compute.amlcompute.AmlCompute object at 0x119814470>\n"
     ]
    }
   ],
   "source": [
    "# choose a name for your cluster\n",
    "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"nv12\")\n",
    "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\n",
    "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n",
    "compute_target = ws.compute_targets[compute_name]\n",
    "print(compute_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your experiment name within the workspace you desire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T12:46:31.624372Z",
     "start_time": "2019-04-12T12:46:31.61571Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment_name = 'machine_translation-transformer'\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the experiment tab, you should see the experiment that you just created on the portal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<img src=\"images/experiment_name.png\" width=\"1500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create estimator and submit an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T20:27:52.50884Z",
     "start_time": "2019-04-10T20:27:52.497699Z"
    }
   },
   "outputs": [],
   "source": [
    "pt_est = PyTorch(source_directory='./', \n",
    "                 script_params=script_params,\n",
    "                 compute_target=compute_target,\n",
    "                 entry_script='transformer.py',\n",
    "                 pip_packages=['torchtext','bert-embedding'], # specify the packages that you need the run to install\n",
    "                 use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-10T20:28:05.264712Z",
     "start_time": "2019-04-10T20:27:53.626915Z"
    }
   },
   "outputs": [],
   "source": [
    "run = exp.submit(pt_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T13:20:03.451056Z",
     "start_time": "2019-04-12T13:20:03.447848Z"
    }
   },
   "source": [
    "### To show widget of the experiment run details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/widget.png\" width=\"1500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can retrieve the logs for the experiment runs in the portal. The individual log files that you see on the portal keeps track of any `print` statements that you have included in your training script. \n",
    "<br>\n",
    "<img src=\"images/log_details.png\" width=\"1500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if you have to submit multiple experiment runs, you do not have to worry about the changes that you make to the scripts because Azure keeps track of the scripts. You can even download a snapshot of your experiment run on the portal.\n",
    "<br>\n",
    "<img src=\"images/snapshot.png\" width=\"1500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the model, let's look at how our transformer model in German translation to English! \n",
    "\n",
    "***German Sentence (Source):***\n",
    "<div style=\"background-color:rgba(0, 0, 0, 0.0470588); text-align:center; vertical-align: middle; padding:40px 0;\" markdown=\"1\"><span style=\"display:block\" visibility=\"visible\">\n",
    "Aber wir hören wenig darüber, dass es da so etwas gibt wie Erwachsenen-Entwicklung und unsere 20er eine ausschlaggebende Zeit dafür sind. \n",
    "    </span>\n",
    "</div>\n",
    "\n",
    "\n",
    "***English Translation from Transfomer (Target)***: \n",
    "<div style=\"background-color:rgba(225, 225, 0, 0.3); text-align:center; vertical-align: middle; padding:40px 0;\" markdown=\"1\"><span style=\"display:block\" visibility=\"visible\">\n",
    "But we hear little bit about that there's something like adults development and our 20s are a suggestion of time.\n",
    "    </span>\n",
    "</div>\n",
    "\n",
    "***English Translation from Online Search Engine***:\n",
    "<div style=\"background-color:rgba(0, 2250, 0, 0.04); text-align:center; vertical-align: middle; padding:40px 0;\" markdown=\"1\"><span style=\"display:block\" visibility=\"visible\">\n",
    "But we hear little about the fact that there is such a thing as adult development and our 20s are a crucial time for it.\n",
    "    </span>\n",
    "</div>\n",
    "\n",
    "We see that the transformer model is not _terrible_ and is able to translate long sentences pretty well (especially the first part!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful to know: cancel runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is useful when you realize you have made mistakes in your submitted training script (for example typos, if you are like me!). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To cancel the last run:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the status of the submitted run. You can see that after running `.cancel()`, the experiment is now cancelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T02:52:50.626457Z",
     "start_time": "2019-04-12T02:52:49.732282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did the run start? Preparing\n",
      "Did the run cancel? Canceled\n"
     ]
    }
   ],
   "source": [
    "local_script_run = exp.submit(pt_est)\n",
    "print(\"Did the run start?\",local_script_run.get_status())\n",
    "\n",
    "local_script_run.cancel()\n",
    "print(\"Did the run cancel?\",local_script_run.get_status())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To cancel a run based on experiment ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you submitted multiple experiments and you want to cancel a specific experiment (because it is no longer relevant), you can retrieve an experiment's `Run Id` to cancel it directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-12T12:53:59.50194Z",
     "start_time": "2019-04-12T12:53:52.977269Z"
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import get_run\n",
    "run_cpu_id = 'machine_translation_1554915123_b8da5e9d' #get from portal\n",
    "run=get_run(exp, run_cpu_id)\n",
    "run.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can also navigate to the experiment run on the portal to use the `cancel` button.\n",
    "<br>\n",
    "<img src=\"images/cancel_runs.png\" width=\"800\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language": "fsharp",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
