{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# *Work in Progress* Machine Translation Project "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "This project aims to translate sentences from German to English. There are in total 200,000 pairs of sentences. The current model script is named as bert_seq2seq_410.py, which contains a bert tokenizer and a vanilla 2-layer encoder-decoder architecture. The model script will continue to be updated over the next few weeks for iterations of better models, for instance transformer model."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Next step: finalize the script and add more explanation around the code blocks."
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-12T12:45:16.596652Z",
          "end_time": "2019-04-12T12:45:30.469377Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport matplotlib.pyplot as plt\n\nimport azureml.core\nfrom azureml.core import Workspace, Experiment, Run, Datastore\n\n# check core SDK version number\nprint(\"Azure ML SDK Version: \", azureml.core.VERSION)",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Azure ML SDK Version:  1.0.17\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-12T12:45:41.924407Z",
          "end_time": "2019-04-12T12:46:30.079394Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "ws = Workspace.from_config()",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Warning: Falling back to use azure cli login credentials.\nIf you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\nPlease refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Found the config file in: /home/nbuser/library/config.json\nPerforming interactive authentication. Please follow the instructions on the terminal.\nTo sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code FQZZLZDSV to authenticate.\nInteractive authentication successfully completed.\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-12T12:46:31.61571Z",
          "end_time": "2019-04-12T12:46:31.624372Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "experiment_name = 'machine_translation'\nexp = Experiment(workspace=ws, name=experiment_name)",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-12T13:16:51.371015Z",
          "end_time": "2019-04-12T13:16:51.375785Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "# load config file\nconfig_path = os.path.join(os.getcwd(), '../config.json')\nwith open(config_path, 'r') as f:\n    config = json.load(f)",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-12T02:58:50.51728Z",
          "end_time": "2019-04-12T02:58:51.863411Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core.compute import AmlCompute\nfrom azureml.core.compute import ComputeTarget\nimport os\n\n# choose a name for your cluster\ncompute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"gpucluster\")\ncompute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\ncompute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n\n# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6/STANDARD_D2_V2\nvm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_STANDARD_NC24\", \"STANDARD_NC24\")\n\nif compute_name in ws.compute_targets:\n    compute_target = ws.compute_targets[compute_name]\n    if compute_target and type(compute_target) is AmlCompute:\n        print('found compute target. just use it. ' + compute_name)\nelse:\n    print('creating a new compute target...')\n    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n                                                                min_nodes = compute_min_nodes, \n                                                                max_nodes = compute_max_nodes)\n\n    # create the cluster\n    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n    \n    # can poll for a minimum number of nodes and for a specific timeout. \n    # if no min node count is provided it will use the scale settings for the cluster\n    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n    \n     # For a more detailed view of current AmlCompute status, use get_status()\n    print(compute_target.get_status().serialize())",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": "found compute target. just use it. gpucluster\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "ExecuteTime": {
          "start_time": "2019-04-12T13:18:46.009089Z",
          "end_time": "2019-04-12T13:18:47.981198Z"
        }
      },
      "cell_type": "code",
      "source": "ds = ws.get_default_datastore()\nprint(ds.datastore_type, ds.account_name, ds.container_name)\n\n# path_on_datastore = 'machine_translation'\n# ds_data = ds.path(path_on_datastore)\n# print(ds_data)\n\n# #define default datastore for current workspace\n# ws.set_default_datastore('machine_translation')\nds = Datastore.register_azure_blob_container(workspace=ws, \n                                             datastore_name='machine_translation', \n                                             container_name=config[\"container_name\"],\n                                             account_name=config[\"account_name\"], \n                                             account_key=config[\"account_key\"],\n                                             create_if_not_exists=True)\n\n#get named datastore from current workspace\nds = Datastore.get(ws, datastore_name='machine_translation')\n\nds.path('./machine_translation').as_download()",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": "AzureBlob amherstwstorageinnganzr azureml-blobstore-fe92660d-c6c1-4086-b2f7-71f9c508e6c7\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 25,
          "data": {
            "text/plain": "$AZUREML_DATAREFERENCE_72d16a4b1fff4322aa511ab4097ca514"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-12T02:59:01.485558Z",
          "end_time": "2019-04-12T02:59:01.498749Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "script_params = {\n    '--data-folder': ds.as_mount() #ds.path('./machine_translation').as_mount() # ds.as_mount()\n}",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "ExecuteTime": {
          "start_time": "2019-04-10T20:27:52.497699Z",
          "end_time": "2019-04-10T20:27:52.50884Z"
        }
      },
      "cell_type": "code",
      "source": "from azureml.train.dnn import PyTorch\n\npt_est = PyTorch(source_directory='./', \n                 script_params=script_params,\n                 compute_target=compute_target,\n                 entry_script='seq2seq_410.py', # copy_of_seq2seq.py # mt_seq2seq_attention.py # new_seq2seq.py\n                 pip_packages=['torchtext','bert-embedding'],\n                 use_gpu=True)",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-10T20:27:53.626915Z",
          "end_time": "2019-04-10T20:28:05.264712Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "run = exp.submit(pt_est)",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-12T02:59:05.706133Z",
          "end_time": "2019-04-12T02:59:17.511434Z"
        },
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from azureml.core import ScriptRunConfig\nfrom azureml.train.dnn import PyTorch\n\npt_est = PyTorch(source_directory='./', \n                 script_params=script_params,\n                 compute_target=compute_target,\n                 entry_script='copy_of_seq2seq.py', # copy_of_seq2seq.py # mt_seq2seq_attention.py # new_seq2seq.py\n                 pip_packages=['torchtext','bert-embedding'],\n                 use_gpu=True)",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Did the run start? Queued\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-12T13:20:03.447848Z",
          "end_time": "2019-04-12T13:20:03.451056Z"
        }
      },
      "cell_type": "markdown",
      "source": "### To show widget of the experiment run details"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.widgets import RunDetails\nRunDetails(run).show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## To cancel the last run:"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-12T02:52:49.732282Z",
          "end_time": "2019-04-12T02:52:50.626457Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "local_script_run = exp.submit(pt_est)\nprint(\"Did the run start?\",local_script_run.get_status())\n\nlocal_script_run.cancel()\nprint(\"Did the run cancel?\",local_script_run.get_status())",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Did the run cancel? Canceled\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## To cancel a run based on experiment ID"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-12T12:53:52.977269Z",
          "end_time": "2019-04-12T12:53:59.50194Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core import get_run\nrun_cpu_id = 'machine_translation_1554915123_b8da5e9d' #get from portal\nrun=get_run(exp, run_cpu_id)\nrun.cancel()",
      "execution_count": 9,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "varInspector": {
      "window_display": false,
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "library": "var_list.py",
          "delete_cmd_prefix": "del ",
          "delete_cmd_postfix": "",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "library": "var_list.r",
          "delete_cmd_prefix": "rm(",
          "delete_cmd_postfix": ") ",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ]
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "base_numbering": 1,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "language": "fsharp"
  },
  "nbformat": 4,
  "nbformat_minor": 1
}