{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Studying News Popularity in terms of Number of Shares"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Courtesy of K. Fernandes, P. Vinagre and P. Cortez. A Proactive Intelligent Decision Support System for Predicting the Popularity of Online News. Proceedings of the 17th EPIA 2015 - Portuguese Conference on Artificial Intelligence, September, Coimbra, Portugal.\n\nRefer to https://archive.ics.uci.edu/ml/datasets/Online+News+Popularity for details. "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "** Table of Content**\n\n1. [Set Up Workspace](#Set-Up-Workspace)\n2. [Define preprocessing script for model training](#Define-preprocessing-script-for-model-training)\n3. [Specify experiment settings and compute targets](#Specify-Experiment-Settings-and-Compute-Targets)\n4. [Submit an experiment](#Submit-an-experiment)\n5. [Explain Model](#Explain-Model)\n6. [Register Model](#Register-Model)\n\n\nTip: if you need to debug your SDK, you can run this line `from azureml._logging.debug_mode import debug_sdk` and call `debug_sdk()` just before the code block you want to debug."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Set Up Workspace"
    },
    {
      "metadata": {
        "trusted": true,
        "ExecuteTime": {
          "start_time": "2019-04-26T00:59:03.736855Z",
          "end_time": "2019-04-26T00:59:07.409228Z"
        }
      },
      "cell_type": "code",
      "source": "import os\nimport pandas as pd\nimport numpy as np\nimport logging\n\n## Read data from a website\nfrom io import BytesIO\nfrom zipfile import ZipFile\nfrom urllib.request import urlopen\n\n## Split data \nfrom sklearn.model_selection import train_test_split\n\n\n## Azure-related\nimport azureml.dataprep as dprep # preprocessing module \nimport azureml.core\nprint(\"SDK version:\", azureml.core.VERSION)\nfrom azureml.core import Workspace, Experiment, Run\n\n### Specify compute targets\nfrom azureml.core.compute import AmlCompute\nfrom azureml.core.compute import ComputeTarget\n",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "SDK version: 1.0.17\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "ExecuteTime": {
          "start_time": "2019-04-26T00:59:10.181541Z",
          "end_time": "2019-04-26T00:59:27.574815Z"
        }
      },
      "cell_type": "code",
      "source": "ws = Workspace.from_config()",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Warning: Falling back to use azure cli login credentials.\nIf you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\nPlease refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Found the config file in: /home/nbuser/library/config.json\nPerforming interactive authentication. Please follow the instructions on the terminal.\nTo sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code FYZ7TLMAG to authenticate.\nInteractive authentication successfully completed.\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Define preprocessing script for model training"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "If you intend to use remote compute, rather than local compute, you should provide your data in a python script as shown below, rather than a series of jupyter cells. If you were to use local compute, you can write your codes as you usually would in a jupyter notebook. An example would be shown later in Section [Submit an experiment](#Submit-an-experiment) to show you how you can supply objects to use either remote or local compute."
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-26T01:00:00.7319Z",
          "end_time": "2019-04-26T01:00:00.741172Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\nproject_folder = os.getcwd()",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-26T01:00:02.042057Z",
          "end_time": "2019-04-26T01:00:02.117976Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%writefile $project_folder/preprocess.py\nimport os\nproject_folder = os.getcwd()\nprint(project_folder)\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\n## Read data from a website\nfrom io import BytesIO\nfrom zipfile import ZipFile\nfrom urllib.request import urlopen\n\ndef get_data():\n    # Read Data from url\n    print('Reading data...')\n    resp = urlopen(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00332/OnlineNewsPopularity.zip\")\n    zipfile = ZipFile(BytesIO(resp.read()))\n    zipfile.namelist()\n    file = 'OnlineNewsPopularity/OnlineNewsPopularity.csv'\n    df = pd.read_csv(zipfile.open(file))\n    \n    # Preprocessing\n    # Remove beginning white space in the columns\n    print('Stripping off white space...')\n    df.rename(columns=lambda x: x.strip(), inplace=True)\n    \n    # Set Target Label\n    # Define number of popularity categories to predict\n    print('Make target categories')\n    share_categories = [1,2,3,4,5]\n    df['share_cat'] = np.array(pd.qcut(df['shares'], 5, share_categories))\n    df['share_cat'].dtype\n    df['share_cat'] = np.array(df['share_cat'].astype('category'))\n    \n    # Split Data\n    # time delta and url are not predictive attributes, exclude them\n    x_df = df[df.columns[2:-2]] # url and time delta are the first two attributes \n    y_df = df[df.columns[-1]]\n    \n    print('Splitting data...')\n    x_train, x_test, y_train, y_test = train_test_split(x_df, y_df, test_size=0.2, \n                                                        random_state=607)\n    \n    return { \"X\": x_train.values, \"y\": y_train.values, \n            \"X_valid\": x_test.values, \"y_valid\": y_test.values}\n",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Overwriting /home/nbuser/library/preprocess.py\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-25T01:50:38.438371Z",
          "end_time": "2019-04-25T01:50:38.442137Z"
        }
      },
      "cell_type": "markdown",
      "source": "### the section below is to give a glimpse into the data set only\nWriting preprocess.py above is the only script needed to submit a model training job"
    },
    {
      "metadata": {
        "trusted": true,
        "ExecuteTime": {
          "start_time": "2019-04-25T01:47:47.839908Z",
          "end_time": "2019-04-25T01:47:47.8742Z"
        }
      },
      "cell_type": "code",
      "source": "project_folder = os.getcwd()\ndata_folder = os.path.join(os.getcwd(), 'data/OnlineNewsPopularity')\nprint(data_folder)\nos.makedirs(data_folder, exist_ok=True)",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/library/data/OnlineNewsPopularity\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "ExecuteTime": {
          "start_time": "2019-04-25T01:47:49.372725Z",
          "end_time": "2019-04-25T01:47:54.523352Z"
        }
      },
      "cell_type": "code",
      "source": "resp = urlopen(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00332/OnlineNewsPopularity.zip\")\nzipfile = ZipFile(BytesIO(resp.read()))\nzipfile.namelist()\nfile = 'OnlineNewsPopularity/OnlineNewsPopularity.csv'\noriginal_df = pd.read_csv(zipfile.open(file))",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-25T01:47:56.210554Z",
          "end_time": "2019-04-25T01:47:56.218073Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "df = original_df",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "ExecuteTime": {
          "start_time": "2019-04-19T14:38:26.943747Z",
          "end_time": "2019-04-19T14:38:26.956406Z"
        }
      },
      "cell_type": "code",
      "source": "df.shape",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "(39644, 61)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-19T14:38:27.892423Z",
          "end_time": "2019-04-19T14:38:27.973284Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.head()",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>url</th>\n      <th>timedelta</th>\n      <th>n_tokens_title</th>\n      <th>n_tokens_content</th>\n      <th>n_unique_tokens</th>\n      <th>n_non_stop_words</th>\n      <th>n_non_stop_unique_tokens</th>\n      <th>num_hrefs</th>\n      <th>num_self_hrefs</th>\n      <th>num_imgs</th>\n      <th>...</th>\n      <th>min_positive_polarity</th>\n      <th>max_positive_polarity</th>\n      <th>avg_negative_polarity</th>\n      <th>min_negative_polarity</th>\n      <th>max_negative_polarity</th>\n      <th>title_subjectivity</th>\n      <th>title_sentiment_polarity</th>\n      <th>abs_title_subjectivity</th>\n      <th>abs_title_sentiment_polarity</th>\n      <th>shares</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>http://mashable.com/2013/01/07/amazon-instant-...</td>\n      <td>731.0</td>\n      <td>12.0</td>\n      <td>219.0</td>\n      <td>0.663594</td>\n      <td>1.0</td>\n      <td>0.815385</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.100000</td>\n      <td>0.7</td>\n      <td>-0.350000</td>\n      <td>-0.600</td>\n      <td>-0.200000</td>\n      <td>0.500000</td>\n      <td>-0.187500</td>\n      <td>0.000000</td>\n      <td>0.187500</td>\n      <td>593</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>http://mashable.com/2013/01/07/ap-samsung-spon...</td>\n      <td>731.0</td>\n      <td>9.0</td>\n      <td>255.0</td>\n      <td>0.604743</td>\n      <td>1.0</td>\n      <td>0.791946</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.033333</td>\n      <td>0.7</td>\n      <td>-0.118750</td>\n      <td>-0.125</td>\n      <td>-0.100000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>711</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>http://mashable.com/2013/01/07/apple-40-billio...</td>\n      <td>731.0</td>\n      <td>9.0</td>\n      <td>211.0</td>\n      <td>0.575130</td>\n      <td>1.0</td>\n      <td>0.663866</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.100000</td>\n      <td>1.0</td>\n      <td>-0.466667</td>\n      <td>-0.800</td>\n      <td>-0.133333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>1500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>http://mashable.com/2013/01/07/astronaut-notre...</td>\n      <td>731.0</td>\n      <td>9.0</td>\n      <td>531.0</td>\n      <td>0.503788</td>\n      <td>1.0</td>\n      <td>0.665635</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.136364</td>\n      <td>0.8</td>\n      <td>-0.369697</td>\n      <td>-0.600</td>\n      <td>-0.166667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>1200</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>http://mashable.com/2013/01/07/att-u-verse-apps/</td>\n      <td>731.0</td>\n      <td>13.0</td>\n      <td>1072.0</td>\n      <td>0.415646</td>\n      <td>1.0</td>\n      <td>0.540890</td>\n      <td>19.0</td>\n      <td>19.0</td>\n      <td>20.0</td>\n      <td>...</td>\n      <td>0.033333</td>\n      <td>1.0</td>\n      <td>-0.220192</td>\n      <td>-0.500</td>\n      <td>-0.050000</td>\n      <td>0.454545</td>\n      <td>0.136364</td>\n      <td>0.045455</td>\n      <td>0.136364</td>\n      <td>505</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 61 columns</p>\n</div>",
            "text/plain": "                                                 url   timedelta  \\\n0  http://mashable.com/2013/01/07/amazon-instant-...       731.0   \n1  http://mashable.com/2013/01/07/ap-samsung-spon...       731.0   \n2  http://mashable.com/2013/01/07/apple-40-billio...       731.0   \n3  http://mashable.com/2013/01/07/astronaut-notre...       731.0   \n4   http://mashable.com/2013/01/07/att-u-verse-apps/       731.0   \n\n    n_tokens_title   n_tokens_content   n_unique_tokens   n_non_stop_words  \\\n0             12.0              219.0          0.663594                1.0   \n1              9.0              255.0          0.604743                1.0   \n2              9.0              211.0          0.575130                1.0   \n3              9.0              531.0          0.503788                1.0   \n4             13.0             1072.0          0.415646                1.0   \n\n    n_non_stop_unique_tokens   num_hrefs   num_self_hrefs   num_imgs   ...     \\\n0                   0.815385         4.0              2.0        1.0   ...      \n1                   0.791946         3.0              1.0        1.0   ...      \n2                   0.663866         3.0              1.0        1.0   ...      \n3                   0.665635         9.0              0.0        1.0   ...      \n4                   0.540890        19.0             19.0       20.0   ...      \n\n    min_positive_polarity   max_positive_polarity   avg_negative_polarity  \\\n0                0.100000                     0.7               -0.350000   \n1                0.033333                     0.7               -0.118750   \n2                0.100000                     1.0               -0.466667   \n3                0.136364                     0.8               -0.369697   \n4                0.033333                     1.0               -0.220192   \n\n    min_negative_polarity   max_negative_polarity   title_subjectivity  \\\n0                  -0.600               -0.200000             0.500000   \n1                  -0.125               -0.100000             0.000000   \n2                  -0.800               -0.133333             0.000000   \n3                  -0.600               -0.166667             0.000000   \n4                  -0.500               -0.050000             0.454545   \n\n    title_sentiment_polarity   abs_title_subjectivity  \\\n0                  -0.187500                 0.000000   \n1                   0.000000                 0.500000   \n2                   0.000000                 0.500000   \n3                   0.000000                 0.500000   \n4                   0.136364                 0.045455   \n\n    abs_title_sentiment_polarity   shares  \n0                       0.187500      593  \n1                       0.000000      711  \n2                       0.000000     1500  \n3                       0.000000     1200  \n4                       0.136364      505  \n\n[5 rows x 61 columns]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Specify Experiment Settings and Compute Targets"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Specify a compute target based on an existing cluster or you can create a new compute target. You can view your existing clusters here \n<br>\n<img src=\"Images/compute_target.png\" width=\"2000\">:"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-26T01:02:26.509373Z",
          "end_time": "2019-04-26T01:02:28.071904Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "# gpucluster is an existing compute target\ncompute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"gpucluster\")\ncompute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\ncompute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n\n# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6/STANDARD_D2_V2\nvm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_STANDARD_NC24\", \"STANDARD_NC24\") \n\nif compute_name in ws.compute_targets:\n    compute_target = ws.compute_targets[compute_name]\n    if compute_target and type(compute_target) is AmlCompute:\n        print('found compute target. just use it. ' + compute_name)\nelse:\n    print('creating a new compute target...')\n    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n                                                                min_nodes = compute_min_nodes, \n                                                                max_nodes = compute_max_nodes)\n\n    # create the cluster\n    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n    \n    # can poll for a minimum number of nodes and for a specific timeout. \n    # if no min node count is provided it will use the scale settings for the cluster\n    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n    \n     # For a more detailed view of current AmlCompute status, use get_status()\n    print(compute_target.get_status().serialize())",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": "found compute target. just use it. gpucluster\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "By using automated machine learning, Azure iterates through appropriate machine learning algorithms depending on your task. The array of models supported is listed [here](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-configure-auto-train). Notice that in the settings below, preprocess flag is set to True. Refer to this [article](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-configure-auto-train?view=azure-dataprep-py#data-pre-processing-and-featurization) to learn what preprocessing steps Azure takes.\n"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-26T01:00:18.105346Z",
          "end_time": "2019-04-26T01:00:18.109417Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "automl_settings = {\n    \"iteration_timeout_minutes\" : 10,\n    \"iterations\" : 10,\n    \"primary_metric\" : 'AUC_weighted',\n    \"verbosity\" : logging.INFO,\n    \"preprocess\": True\n}",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-19T20:31:43.413827Z",
          "end_time": "2019-04-19T20:31:43.435892Z"
        }
      },
      "cell_type": "markdown",
      "source": "You can specify your experiment settings as such. Since I am interested in using remote compute target, I am turning the flag `local_compute` to be False. Note the difference between two settings in terms of how you can supply the objects. Beyond what's specified as a parameter in the settings, you can also provide other parameters according to your needs as well. You can refer to [this web page](https://docs.microsoft.com/en-us/python/api/azureml-train-automl/azureml.train.automl.automlconfig?view=azure-ml-py) to read about other parameters."
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-26T01:02:30.548308Z",
          "end_time": "2019-04-26T01:02:30.556994Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.train.automl import AutoMLConfig\n\nlocal_compute = False\n\nif local_compute: \n    print('using local compute')\n    automated_ml_config = AutoMLConfig(task = 'classification',\n                                 debug_log = 'automated_ml_errors.log',\n                                 compute_target=compute_target,\n                                 path = project_folder,\n                                 X = x_train.values,\n                                 y = y_train_array,\n                                 X_valid = x_test.values,\n                                 **automl_settings)\nelse: \n    print('using remote compute')\n    automated_ml_config = AutoMLConfig(task = 'classification',\n                                 debug_log = 'automated_ml_errors.log',\n                                 compute_target=compute_target,\n                                 path = project_folder,\n                                 data_script= project_folder + \"/get_data.py\",\n                                 model_explainability=True,\n                                 **automl_settings)",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": "using remote compute\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-03-29T00:56:01.396951Z",
          "end_time": "2019-03-29T00:56:01.399727Z"
        }
      },
      "cell_type": "markdown",
      "source": "# Submit an experiment"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now that you have defined your experiment settings above, you can create and name the experiment to run in the workspace you desired. \n<br>\n<img src=\"Images/experiment_homepage.png\" width=\"1500\">",
      "attachments": {}
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-26T01:05:18.889783Z",
          "end_time": "2019-04-26T01:05:18.8994Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "# create an experiment\nexperiment = Experiment(workspace = ws, name = \"news_popularity\")",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Next, submit the experiment. If you wish to view the output within the notebook, turn on the flag `show_output`."
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-25T02:10:38.695Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "# submit an experiment\nrun = experiment.submit(automated_ml_config, show_output=True)",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/library\nReading data...\nStripping off white space...\nMake target categories\nSplitting data...\nRunning on remote compute: gpucluster\nParent Run ID: AutoML_2e02b696-bf8a-47f4-b035-64347532b27e\n********************************************************************************************************************\nITERATION: The iteration being evaluated.\nPIPELINE: A summary description of the pipeline being evaluated.\nSAMPLING %: Percent of the training data to sample.\nDURATION: Time taken for the current iteration.\nMETRIC: The result of computing score on the fitted pipeline.\nBEST: The best observed score thus far.\n********************************************************************************************************************\n\n ITERATION   PIPELINE                                       SAMPLING %  DURATION      METRIC      BEST\n         0   StandardScalerWrapper SGD                      100.0000    0:26:46       0.6304    0.6304\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-26T01:03:40.856755Z",
          "end_time": "2019-04-26T01:03:40.882577Z"
        }
      },
      "cell_type": "markdown",
      "source": "Different runs of the same experiment name will be grouped under the same parent run.\n\n<br>\n<img src=\"Images/experiment_runs.png\" width=\"1000\">"
    },
    {
      "metadata": {
        "trusted": true,
        "ExecuteTime": {
          "start_time": "2019-04-26T01:05:26.595311Z",
          "end_time": "2019-04-26T01:05:26.642085Z"
        }
      },
      "cell_type": "code",
      "source": "from azureml.widgets import RunDetails\nRunDetails(run).show()",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad76e348da524438ba75e468b72b1b02",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<img src=\"Images/run_output_details.png\" width=\"1500\">"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "###  Retrieve the Best Model"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "You can retrieve the best model based on the run that you just defined above."
    },
    {
      "metadata": {
        "trusted": true,
        "ExecuteTime": {
          "start_time": "2019-04-06T23:40:04.685532Z",
          "end_time": "2019-04-06T23:40:18.724295Z"
        }
      },
      "cell_type": "code",
      "source": "best_run, fitted_model = run.get_output()\nprint(best_run)\nprint(fitted_model)",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Run(Experiment: news_popularity,\nId: AutoML_96d26b44-876a-4643-b56f-6250e616e123_29,\nType: None,\nStatus: Completed)\nPipeline(memory=None,\n     steps=[('datatransformer', DataTransformer(logger=None, task=None)), ('prefittedsoftvotingclassifier', PreFittedSoftVotingClassifier(classification_labels=None,\n               estimators=[('LightGBM', Pipeline(memory=None,\n     steps=[('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ...666666666667, 0.06666666666666667, 0.26666666666666666, 0.13333333333333333, 0.26666666666666666]))])\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Best Model Based on Any Other Metric"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Even though I specified `AUC_weighted` to be the metric that I wanted to measure against, I can also choose other relevant metrics to pick the best model. In the following cell, I am interested in looking up the model that has the highest accuracy rate."
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-06T23:40:47.836234Z",
          "end_time": "2019-04-06T23:41:02.78916Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "lookup_metric = \"accuracy\"\nbest_run, fitted_model = run.get_output(metric = lookup_metric)\nprint(best_run)\nprint(fitted_model)",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Run(Experiment: news_popularity,\nId: AutoML_96d26b44-876a-4643-b56f-6250e616e123_29,\nType: None,\nStatus: Completed)\nPipeline(memory=None,\n     steps=[('datatransformer', DataTransformer(logger=None, task=None)), ('prefittedsoftvotingclassifier', PreFittedSoftVotingClassifier(classification_labels=None,\n               estimators=[('LightGBM', Pipeline(memory=None,\n     steps=[('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ...666666666667, 0.06666666666666667, 0.26666666666666666, 0.13333333333333333, 0.26666666666666666]))])\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## To retrieve the best model run without re-training"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "There are also times when you wish to retrieve the best model run, without having to re-define your model objects again. In this scenario, you can head to the home page of your desired experiment to obtain the `Run Id` of the experiment.\n<br>\n<img src=\"Images/run_id.png\" width=\"1500\">"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-22T00:32:05.059226Z",
          "end_time": "2019-04-22T00:32:05.907468Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core import get_run\nrun_cpu_id = 'AutoML_fd9055d1-1f4b-4484-ae70-d773ca82bd67_1' #get from portal\nbest_run = get_run(experiment, run_cpu_id)",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Explain Model"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Since I included the flag `model_explanability` in my `automated_ml_config` settings (refer to Section [Specify Experiment Settings and Compute Targets](#Specify-Experiment-Settings-and-Compute-Targets)], I can easily retrieve model explanation. To learn about the `automlexplainer` module, you can visit this [page](https://docs.microsoft.com/en-us/python/api/azureml-train-automl/azureml.train.automl.automlexplainer?view=azure-ml-py) to gain more information."
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-26T01:19:11.132281Z",
          "end_time": "2019-04-26T01:19:11.135854Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "best_run = run",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "You can choose to print to view overall and class-level feature importance in the notebook, or you can navigate to the portal to view a ready-made chart that compares feature importance. "
    },
    {
      "metadata": {
        "trusted": true,
        "ExecuteTime": {
          "start_time": "2019-04-26T01:21:32.580216Z",
          "end_time": "2019-04-26T01:21:59.963346Z"
        }
      },
      "cell_type": "code",
      "source": "# if there is problem in importing `numpy.core.multiarray`, upgrade your numpy package\n# !pip install -U numpy\nfrom azureml.train.automl.automlexplainer import retrieve_model_explanation\n\n## for a specific run \nshap_values, expected_values, overall_summary, overall_imp, per_class_summary, per_class_imp = \\\n    retrieve_model_explanation(best_run)\n\n# Overall feature importance\n# print(overall_imp)\n# print(overall_summary)\n\n# Class-level feature importance\n# print(per_class_imp)\n# print(per_class_summary)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-26T01:23:07.596168Z",
          "end_time": "2019-04-26T01:23:07.619357Z"
        }
      },
      "cell_type": "markdown",
      "source": "<br>\nThe block above will also create a folder within your project directory to save `explanation` in json files.\n<br>\n<img src=\"Images/explanation.png\" width=\"1500\">"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "If you would like to retrieve feature importance chart, go to your portal and click on the experiment run you are interested in to view it. \n<br>\n<img src=\"Images/explanation_chart.png\" width=\"500\">"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Register Model"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Finally, if you are interested in hosting your model online, you can register your model! Now, you can go on and connect your webpage with your model or do batch scoring if you would like to!"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-20T18:16:43.928666Z",
          "end_time": "2019-04-20T18:16:45.713841Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "model = best_run.register_model('predict_news_popularity')",
      "execution_count": 36,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<br>\n<img src=\"Images/register_model.png\" width=\"1000\">"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "varInspector": {
      "window_display": false,
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "library": "var_list.py",
          "delete_cmd_prefix": "del ",
          "delete_cmd_postfix": "",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "library": "var_list.r",
          "delete_cmd_prefix": "rm(",
          "delete_cmd_postfix": ") ",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ]
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "base_numbering": 1,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}