{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Studying News Popularity in terms of Number of Shares"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Courtesy of K. Fernandes, P. Vinagre and P. Cortez. A Proactive Intelligent Decision Support System for Predicting the Popularity of Online News. Proceedings of the 17th EPIA 2015 - Portuguese Conference on Artificial Intelligence, September, Coimbra, Portugal.\n\nRefer to https://archive.ics.uci.edu/ml/datasets/Online+News+Popularity for details. "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "** Table of Content**\n\n1. [Set Up Workspace](#Set-Up-Workspace)\n2. [Define preprocessing script for model training](#Define-preprocessing-script-for-model-training)\n3. [Specify experiment settings and compute targets](#Specify-Experiment-Settings-and-Compute-Targets)\n4. [Submit an experiment](#Submit-an-experiment)\n5. [Explain Model](#Explain-Model)\n6. [Register Model](#Register-Model)\n\n\nTip: if you need to debug your SDK, you can run this line `from azureml._logging.debug_mode import debug_sdk` and call `debug_sdk()` just before the code block you want to debug."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Set Up Workspace"
    },
    {
      "metadata": {
        "trusted": true,
        "ExecuteTime": {
          "start_time": "2019-05-05T02:27:34.92825Z",
          "end_time": "2019-05-05T02:27:37.469515Z"
        }
      },
      "cell_type": "code",
      "source": "import os\nimport pandas as pd\nimport numpy as np\nimport logging\n\n## Read data from a website\nfrom io import BytesIO\nfrom zipfile import ZipFile\nfrom urllib.request import urlopen\n\n## Split data \nfrom sklearn.model_selection import train_test_split\n\n\n## Azure-related\nimport azureml.core\nprint(\"SDK version:\", azureml.core.VERSION)\nfrom azureml.core import Workspace, Experiment, Run\n\n### Specify compute targets\nfrom azureml.core.compute import AmlCompute\nfrom azureml.core.compute import ComputeTarget\n",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "SDK version: 1.0.33\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "ExecuteTime": {
          "start_time": "2019-05-05T02:27:40.833616Z",
          "end_time": "2019-05-05T02:27:41.939989Z"
        }
      },
      "cell_type": "code",
      "source": "ws = Workspace.from_config()",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-05-05T02:27:44.945205Z",
          "end_time": "2019-05-05T02:27:44.951116Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(\"This notebook was validated with the AzureML SDK version 1.0.33. You are currently using \", azureml.core.VERSION)",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "This notebook was validated with the AzureML SDK version 1.0.33. You are currently using  1.0.33\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Define preprocessing script for model training"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "If you intend to use remote compute, rather than local compute, you should provide your data in a python script as shown below, rather than a series of jupyter cells. If you were to use local compute, you can write your codes as you usually would in a jupyter notebook. An example would be shown later in Section [Specify Experiment Settings and Compute Targets](#Specify-Experiment-Settings-and-Compute-Targets) to show you how you can supply objects to use either remote or local compute."
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-05-05T02:27:51.135309Z",
          "end_time": "2019-05-05T02:27:51.143392Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\nproject_folder = os.getcwd()",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-05-05T01:48:33.666632Z",
          "end_time": "2019-05-05T01:48:34.011568Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "%%writefile $project_folder/preprocess.py\nimport os\nproject_folder = os.getcwd()\nprint(project_folder)\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\n## Read data from a website\nfrom io import BytesIO\nfrom zipfile import ZipFile\nfrom urllib.request import urlopen\n\ndef get_data():\n    # Read Data from url\n    print('Reading data...')\n    resp = urlopen(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00332/OnlineNewsPopularity.zip\")\n    zipfile = ZipFile(BytesIO(resp.read()))\n    zipfile.namelist()\n    file = 'OnlineNewsPopularity/OnlineNewsPopularity.csv'\n    df = pd.read_csv(zipfile.open(file))\n    \n    # Preprocessing\n    # Remove beginning white space in the columns\n    print('Stripping off white space...')\n    df.rename(columns=lambda x: x.strip(), inplace=True)\n    \n    # Set Target Label\n    # Define number of popularity categories to predict\n    print('Make target categories')\n    share_categories = [1,2,3,4,5]\n    df['share_cat'] = np.array(pd.qcut(df['shares'], 5, share_categories))\n    df['share_cat'].dtype\n    df['share_cat'] = np.array(df['share_cat'].astype('category'))\n    \n    # Split Data\n    # time delta and url are not predictive attributes, exclude them\n    x_df = df[df.columns[2:-2]] # url and time delta are the first two attributes \n    y_df = df[df.columns[-1]]\n    \n    print('Splitting data...')\n    x_train, x_test, y_train, y_test = train_test_split(x_df, y_df, test_size=0.2, \n                                                        random_state=607)\n    \n    return { \"X\": x_train.values, \"y\": y_train.values, \n            \"X_valid\": x_test.values, \"y_valid\": y_test.values}\n",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Overwriting /home/nbuser/library/preprocess.py\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-25T01:50:38.438371Z",
          "end_time": "2019-04-25T01:50:38.442137Z"
        }
      },
      "cell_type": "markdown",
      "source": "### Data Understanding\nThis section aims only to give a glimpse into the data set. Writing preprocess.py above is the only script needed to submit a model training job"
    },
    {
      "metadata": {
        "trusted": true,
        "ExecuteTime": {
          "start_time": "2019-05-05T02:27:53.692997Z",
          "end_time": "2019-05-05T02:27:53.733876Z"
        }
      },
      "cell_type": "code",
      "source": "project_folder = os.getcwd()\ndata_folder = os.path.join(os.getcwd(), 'data/OnlineNewsPopularity')\nprint(data_folder)\nos.makedirs(data_folder, exist_ok=True)",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/library/data/OnlineNewsPopularity\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "ExecuteTime": {
          "start_time": "2019-05-05T02:27:56.847262Z",
          "end_time": "2019-05-05T02:27:59.020804Z"
        }
      },
      "cell_type": "code",
      "source": "resp = urlopen(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00332/OnlineNewsPopularity.zip\")\nzipfile = ZipFile(BytesIO(resp.read()))\nzipfile.namelist()\nfile = 'OnlineNewsPopularity/OnlineNewsPopularity.csv'\noriginal_df = pd.read_csv(zipfile.open(file))\n\ndf = original_df\ndf.shape",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "(39644, 61)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We are inspecting the data frame to make sure that the data looks correct. Note that the first and second columns are not predictive, hence they are not included in the training data set as predictors. The url column gives the URL of the article whereas `timedelta` is the number of days between the article publication and the dataset acquisition. For the complete list of description of each columns, refer to this [page](https://archive.ics.uci.edu/ml/datasets/Online+News+Popularity#)."
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-19T14:38:27.892423Z",
          "end_time": "2019-04-19T14:38:27.973284Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.head()",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>url</th>\n      <th>timedelta</th>\n      <th>n_tokens_title</th>\n      <th>n_tokens_content</th>\n      <th>n_unique_tokens</th>\n      <th>n_non_stop_words</th>\n      <th>n_non_stop_unique_tokens</th>\n      <th>num_hrefs</th>\n      <th>num_self_hrefs</th>\n      <th>num_imgs</th>\n      <th>...</th>\n      <th>min_positive_polarity</th>\n      <th>max_positive_polarity</th>\n      <th>avg_negative_polarity</th>\n      <th>min_negative_polarity</th>\n      <th>max_negative_polarity</th>\n      <th>title_subjectivity</th>\n      <th>title_sentiment_polarity</th>\n      <th>abs_title_subjectivity</th>\n      <th>abs_title_sentiment_polarity</th>\n      <th>shares</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>http://mashable.com/2013/01/07/amazon-instant-...</td>\n      <td>731.0</td>\n      <td>12.0</td>\n      <td>219.0</td>\n      <td>0.663594</td>\n      <td>1.0</td>\n      <td>0.815385</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.100000</td>\n      <td>0.7</td>\n      <td>-0.350000</td>\n      <td>-0.600</td>\n      <td>-0.200000</td>\n      <td>0.500000</td>\n      <td>-0.187500</td>\n      <td>0.000000</td>\n      <td>0.187500</td>\n      <td>593</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>http://mashable.com/2013/01/07/ap-samsung-spon...</td>\n      <td>731.0</td>\n      <td>9.0</td>\n      <td>255.0</td>\n      <td>0.604743</td>\n      <td>1.0</td>\n      <td>0.791946</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.033333</td>\n      <td>0.7</td>\n      <td>-0.118750</td>\n      <td>-0.125</td>\n      <td>-0.100000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>711</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>http://mashable.com/2013/01/07/apple-40-billio...</td>\n      <td>731.0</td>\n      <td>9.0</td>\n      <td>211.0</td>\n      <td>0.575130</td>\n      <td>1.0</td>\n      <td>0.663866</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.100000</td>\n      <td>1.0</td>\n      <td>-0.466667</td>\n      <td>-0.800</td>\n      <td>-0.133333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>1500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>http://mashable.com/2013/01/07/astronaut-notre...</td>\n      <td>731.0</td>\n      <td>9.0</td>\n      <td>531.0</td>\n      <td>0.503788</td>\n      <td>1.0</td>\n      <td>0.665635</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.136364</td>\n      <td>0.8</td>\n      <td>-0.369697</td>\n      <td>-0.600</td>\n      <td>-0.166667</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>1200</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>http://mashable.com/2013/01/07/att-u-verse-apps/</td>\n      <td>731.0</td>\n      <td>13.0</td>\n      <td>1072.0</td>\n      <td>0.415646</td>\n      <td>1.0</td>\n      <td>0.540890</td>\n      <td>19.0</td>\n      <td>19.0</td>\n      <td>20.0</td>\n      <td>...</td>\n      <td>0.033333</td>\n      <td>1.0</td>\n      <td>-0.220192</td>\n      <td>-0.500</td>\n      <td>-0.050000</td>\n      <td>0.454545</td>\n      <td>0.136364</td>\n      <td>0.045455</td>\n      <td>0.136364</td>\n      <td>505</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 61 columns</p>\n</div>",
            "text/plain": "                                                 url   timedelta  \\\n0  http://mashable.com/2013/01/07/amazon-instant-...       731.0   \n1  http://mashable.com/2013/01/07/ap-samsung-spon...       731.0   \n2  http://mashable.com/2013/01/07/apple-40-billio...       731.0   \n3  http://mashable.com/2013/01/07/astronaut-notre...       731.0   \n4   http://mashable.com/2013/01/07/att-u-verse-apps/       731.0   \n\n    n_tokens_title   n_tokens_content   n_unique_tokens   n_non_stop_words  \\\n0             12.0              219.0          0.663594                1.0   \n1              9.0              255.0          0.604743                1.0   \n2              9.0              211.0          0.575130                1.0   \n3              9.0              531.0          0.503788                1.0   \n4             13.0             1072.0          0.415646                1.0   \n\n    n_non_stop_unique_tokens   num_hrefs   num_self_hrefs   num_imgs   ...     \\\n0                   0.815385         4.0              2.0        1.0   ...      \n1                   0.791946         3.0              1.0        1.0   ...      \n2                   0.663866         3.0              1.0        1.0   ...      \n3                   0.665635         9.0              0.0        1.0   ...      \n4                   0.540890        19.0             19.0       20.0   ...      \n\n    min_positive_polarity   max_positive_polarity   avg_negative_polarity  \\\n0                0.100000                     0.7               -0.350000   \n1                0.033333                     0.7               -0.118750   \n2                0.100000                     1.0               -0.466667   \n3                0.136364                     0.8               -0.369697   \n4                0.033333                     1.0               -0.220192   \n\n    min_negative_polarity   max_negative_polarity   title_subjectivity  \\\n0                  -0.600               -0.200000             0.500000   \n1                  -0.125               -0.100000             0.000000   \n2                  -0.800               -0.133333             0.000000   \n3                  -0.600               -0.166667             0.000000   \n4                  -0.500               -0.050000             0.454545   \n\n    title_sentiment_polarity   abs_title_subjectivity  \\\n0                  -0.187500                 0.000000   \n1                   0.000000                 0.500000   \n2                   0.000000                 0.500000   \n3                   0.000000                 0.500000   \n4                   0.136364                 0.045455   \n\n    abs_title_sentiment_polarity   shares  \n0                       0.187500      593  \n1                       0.000000      711  \n2                       0.000000     1500  \n3                       0.000000     1200  \n4                       0.136364      505  \n\n[5 rows x 61 columns]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Specify Experiment Settings and Compute Targets"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Specify a compute target based on an existing cluster or you can create a new compute target. You can view your existing clusters here \n<br>\n<img src=\"Images/compute_target.png\" width=\"2000\">:"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-05-05T02:28:03.887047Z",
          "end_time": "2019-05-05T02:28:04.403654Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "# gpucluster is an existing compute target\ncompute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"gpucluster\")\ncompute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\ncompute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n\ncompute_target = ws.compute_targets[compute_name]",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "By using automated machine learning, Azure iterates through appropriate machine learning algorithms depending on your task. The array of models supported is listed [here](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-configure-auto-train). Notice that in the settings below, preprocess flag is set to True. Refer to this [article](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-configure-auto-train?view=azure-dataprep-py#data-pre-processing-and-featurization) to learn what preprocessing steps Azure takes.\n"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-05-05T02:28:05.64824Z",
          "end_time": "2019-05-05T02:28:05.652441Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "automl_settings = {\n    \"iteration_timeout_minutes\" : 10,\n    \"iterations\" : 10,\n    \"primary_metric\" : 'AUC_weighted',\n    \"verbosity\" : logging.INFO,\n    \"preprocess\": True\n}",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-19T20:31:43.413827Z",
          "end_time": "2019-04-19T20:31:43.435892Z"
        }
      },
      "cell_type": "markdown",
      "source": "You can specify your experiment settings as such. Since I am interested in using remote compute target, I am turning the flag `local_compute` to be False. Note the difference between two settings in terms of how you can supply the objects. Beyond what's specified as a parameter in the settings, you can also provide other parameters according to your needs as well. You can refer to [this web page](https://docs.microsoft.com/en-us/python/api/azureml-train-automl/azureml.train.automl.automlconfig?view=azure-ml-py) to read about other parameters."
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-05-05T02:28:07.916806Z",
          "end_time": "2019-05-05T02:28:10.806391Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.train.automl import AutoMLConfig\n\nlocal_compute = False\n\nif local_compute: \n    print('using local compute')\n    automated_ml_config = AutoMLConfig(task = 'classification',\n                                 debug_log = 'automated_ml_errors.log',\n                                 compute_target=compute_target,\n                                 path = project_folder,\n                                 X = x_train.values,\n                                 y = y_train_array,\n                                 X_valid = x_test.values,\n                                 **automl_settings)\nelse: \n    print('using remote compute')\n    automated_ml_config = AutoMLConfig(task = 'classification',\n                                 debug_log = 'automated_ml_errors.log',\n                                 compute_target=compute_target,\n                                 path = project_folder,\n                                 data_script= project_folder + \"/get_data.py\",\n                                 model_explainability=True,\n                                 **automl_settings)",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "using remote compute\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-03-29T00:56:01.396951Z",
          "end_time": "2019-03-29T00:56:01.399727Z"
        }
      },
      "cell_type": "markdown",
      "source": "# Submit an experiment"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now that you have defined your experiment settings above, you can create and name the experiment to run in the workspace you desired. \n<br>\n<img src=\"Images/experiment_homepage.png\" width=\"1500\">"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-05-05T02:28:14.677407Z",
          "end_time": "2019-05-05T02:28:14.687117Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "# create an experiment\nexperiment = Experiment(workspace = ws, name = \"news_popularity\")",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Next, submit the experiment. If you wish to view the output within the notebook, turn on the flag `show_output`."
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-25T02:10:38.695Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "# submit an experiment\nrun = experiment.submit(automated_ml_config, show_output=True)",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/library\nReading data...\nStripping off white space...\nMake target categories\nSplitting data...\nRunning on remote compute: gpucluster\nParent Run ID: AutoML_2e02b696-bf8a-47f4-b035-64347532b27e\n********************************************************************************************************************\nITERATION: The iteration being evaluated.\nPIPELINE: A summary description of the pipeline being evaluated.\nSAMPLING %: Percent of the training data to sample.\nDURATION: Time taken for the current iteration.\nMETRIC: The result of computing score on the fitted pipeline.\nBEST: The best observed score thus far.\n********************************************************************************************************************\n\n ITERATION   PIPELINE                                       SAMPLING %  DURATION      METRIC      BEST\n         0   StandardScalerWrapper SGD                      100.0000    0:26:46       0.6304    0.6304\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-26T01:03:40.856755Z",
          "end_time": "2019-04-26T01:03:40.882577Z"
        }
      },
      "cell_type": "markdown",
      "source": "Different runs of the same experiment name will be grouped under the same parent run.\n\n<br>\n<img src=\"Images/experiment_runs.png\" width=\"1000\">"
    },
    {
      "metadata": {
        "trusted": true,
        "ExecuteTime": {
          "start_time": "2019-04-26T01:05:26.595311Z",
          "end_time": "2019-04-26T01:05:26.642085Z"
        }
      },
      "cell_type": "code",
      "source": "from azureml.widgets import RunDetails\nRunDetails(run).show()",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad76e348da524438ba75e468b72b1b02",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<img src=\"Images/run_output_details.png\" width=\"1500\">"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "###  Retrieve the Best Model"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "You can retrieve the best model based on the run that you just defined above."
    },
    {
      "metadata": {
        "trusted": true,
        "ExecuteTime": {
          "start_time": "2019-04-06T23:40:04.685532Z",
          "end_time": "2019-04-06T23:40:18.724295Z"
        }
      },
      "cell_type": "code",
      "source": "best_run, fitted_model = run.get_output()\nprint(best_run)\nprint(fitted_model)",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Run(Experiment: news_popularity,\nId: AutoML_96d26b44-876a-4643-b56f-6250e616e123_29,\nType: None,\nStatus: Completed)\nPipeline(memory=None,\n     steps=[('datatransformer', DataTransformer(logger=None, task=None)), ('prefittedsoftvotingclassifier', PreFittedSoftVotingClassifier(classification_labels=None,\n               estimators=[('LightGBM', Pipeline(memory=None,\n     steps=[('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ...666666666667, 0.06666666666666667, 0.26666666666666666, 0.13333333333333333, 0.26666666666666666]))])\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Best Model Based on Any Other Metric"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Even though I specified `AUC_weighted` to be the metric that I wanted to measure against, I can also choose other relevant metrics to pick the best model. In the following cell, I am interested in looking up the model that has the highest accuracy rate."
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-06T23:40:47.836234Z",
          "end_time": "2019-04-06T23:41:02.78916Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "lookup_metric = \"accuracy\"\nbest_run, fitted_model = run.get_output(metric = lookup_metric)\nprint(best_run)\nprint(fitted_model)",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Run(Experiment: news_popularity,\nId: AutoML_96d26b44-876a-4643-b56f-6250e616e123_29,\nType: None,\nStatus: Completed)\nPipeline(memory=None,\n     steps=[('datatransformer', DataTransformer(logger=None, task=None)), ('prefittedsoftvotingclassifier', PreFittedSoftVotingClassifier(classification_labels=None,\n               estimators=[('LightGBM', Pipeline(memory=None,\n     steps=[('minmaxscaler', MinMaxScaler(copy=True, feature_range=(0, 1))), ...666666666667, 0.06666666666666667, 0.26666666666666666, 0.13333333333333333, 0.26666666666666666]))])\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## To retrieve the best model run without re-training"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "There are also times when you wish to retrieve the best model run, without having to re-define your model objects again. In this scenario, you can head to the home page of your desired experiment to obtain the `Run Id` of the experiment.\n<br>\n<img src=\"Images/run_id.png\" width=\"1500\">"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-05-05T02:28:24.499369Z",
          "end_time": "2019-05-05T02:28:25.137958Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core import get_run\nrun_cpu_id = 'AutoML_2e02b696-bf8a-47f4-b035-64347532b27e_9'\n# run_cpu_id = 'AutoML_fd9055d1-1f4b-4484-ae70-d773ca82bd67' #get from portal\nbest_run = get_run(experiment, run_cpu_id)",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Explain Model"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Model explanability is important for any model users to understand why the model gives a particular outcome. Azure incorporates this explanability option in `automated_ml_config` settings easily for people who want to retrieve model explanation while using the `automl` functionality. \n\nSince I included the flag `model_explanability` in my `automated_ml_config` settings (refer to the last cell under Section [Specify Experiment Settings and Compute Targets](#Specify-Experiment-Settings-and-Compute-Targets)], I can easily retrieve model explanation. To learn about the `automlexplainer` module and the objects returned by `retrieve_model_explanation`, you can visit this [page](https://docs.microsoft.com/en-us/python/api/azureml-train-automl/azureml.train.automl.automlexplainer?view=azure-ml-py) to gain more information. `shap_values` below returns a matrix of feature importance values. The dimension of this matrix is (# examples x # features)."
    },
    {
      "metadata": {
        "trusted": true,
        "ExecuteTime": {
          "start_time": "2019-05-05T02:28:29.407602Z",
          "end_time": "2019-05-05T02:28:55.760951Z"
        }
      },
      "cell_type": "code",
      "source": "# if there is problem in importing `numpy.core.multiarray`, upgrade your numpy package\n# !pip install -U numpy\nfrom azureml.train.automl.automlexplainer import retrieve_model_explanation\n\n## for a specific run \nshap_values, expected_values, overall_summary, overall_imp, per_class_summary, per_class_imp = \\\n    retrieve_model_explanation(best_run)",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "You can inspect overall feature importance and their importance values as shown below. `overall_imp` shows features in decreasing importance whereas `overall_summary` gives the importance values of the associated features. If you are interested in class-level importance features and values, you can print `per_class_imp` and `per_class_summary` to take a look."
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-05-05T02:31:13.317269Z",
          "end_time": "2019-05-05T02:31:13.323016Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(overall_imp)\nprint(overall_summary)",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['C26_MeanImputer', 'C27_MeanImputer', 'C29_MeanImputer', 'C25_MeanImputer', 'C37_MeanImputer', 'C38_MeanImputer', 'C42_MeanImputer', 'C13_MeanImputer', 'C40_MeanImputer', 'C16_MeanImputer', 'C24_MeanImputer', 'C6_MeanImputer', 'C39_MeanImputer', 'C18_MeanImputer', 'C3_MeanImputer', 'C41_MeanImputer', 'C8_MeanImputer', 'C43_MeanImputer', 'C20_MeanImputer', 'C17_MeanImputer', 'C21_MeanImputer', 'C28_MeanImputer', 'C50_MeanImputer', 'C22_MeanImputer', 'C5_MeanImputer', 'C23_MeanImputer', 'C15_MeanImputer', 'C48_MeanImputer', 'C44_MeanImputer', 'C2_MeanImputer', 'C19_MeanImputer', 'C14_MeanImputer', 'C10_MeanImputer', 'C55_MeanImputer', 'C7_MeanImputer', 'C11_MeanImputer', 'C45_MeanImputer', 'C35_MeanImputer', 'C47_MeanImputer', 'C56_MeanImputer', 'C49_MeanImputer', 'C32_MeanImputer', 'C58_MeanImputer', 'C52_MeanImputer', 'C46_MeanImputer', 'C53_MeanImputer', 'C57_MeanImputer', 'C34_MeanImputer', 'C1_MeanImputer', 'C51_MeanImputer', 'C36_MeanImputer', 'C33_MeanImputer', 'C9_MeanImputer', 'C31_MeanImputer', 'C12_MeanImputer', 'C54_MeanImputer', 'C30_MeanImputer', 'C4_MeanImputer']\n[0.019712541051081816, 0.011424979830049828, 0.009658399804934988, 0.006851821993258679, 0.004574793634707667, 0.004495709939540501, 0.004331873373083592, 0.004050282592803406, 0.003287664222611883, 0.0032162906634090617, 0.0030033247533352613, 0.002694387394232299, 0.0024878247574824917, 0.0024849149750631487, 0.002318513625502904, 0.002221067869598961, 0.0021532683649693888, 0.002124515331222745, 0.0017555396014881468, 0.0017173472874164905, 0.0016450763458684243, 0.0016194157647393028, 0.001592435143584927, 0.0015415152618169533, 0.0015329557932204365, 0.001429526437409881, 0.0013843429811544357, 0.0012957338110273968, 0.0012412702252468817, 0.0012123347818488142, 0.0010562672423392397, 0.0010054289158556364, 0.0009937788085746457, 0.0009122608106816815, 0.0009055730763313037, 0.0008289701504379406, 0.0005369651740324115, 0.0005147863544524101, 0.0004327721201554305, 0.00042700645392681894, 0.0004070816519446438, 0.00039420538498104857, 0.0003885971616299993, 0.0003674256612315384, 0.0003570471851366224, 0.0003555112395012789, 0.0003254281461649867, 0.00031565572411514846, 0.0003024163861933807, 0.000292969579408551, 0.00025230470977778696, 0.00020832034483549052, 0.00018955881015356806, 0.00018267571166102341, 0.00015409977402421055, 0.00013564936039205943, 8.048415623649536e-05, 8.625687791397395e-06]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-26T01:23:07.596168Z",
          "end_time": "2019-04-26T01:23:07.619357Z"
        }
      },
      "cell_type": "markdown",
      "source": "<br>\nThe block above will also create a folder within your project directory to save `explanation` in json files.\n<br>\n<img src=\"Images/explanation.png\" width=\"1500\">"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "If you would like to retrieve feature importance chart, go to your portal and click on the experiment run you are interested in to view it. \n<br>\n<img src=\"Images/explanation_chart.png\" width=\"500\">"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Register Model"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Finally, if you are interested in hosting your model online, you can register your model! Now, you can go on to deploy your model and connect your webpage with your model or do batch scoring if you would like to! \n\nTypically, deployment follows three steps:\n\n1. Register model (shown here below!)\n2. Deploy model\n3. Test your deployed model\n\nYou can refer [this page](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-deploy-and-where) to learn how to deploy your model to production locally or on a specific cluster/compute target."
    },
    {
      "metadata": {
        "ExecuteTime": {
          "start_time": "2019-04-20T18:16:43.928666Z",
          "end_time": "2019-04-20T18:16:45.713841Z"
        },
        "trusted": true
      },
      "cell_type": "code",
      "source": "model = best_run.register_model('predict_news_popularity')",
      "execution_count": 36,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<br>\n<img src=\"Images/register_model.png\" width=\"1000\">"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "varInspector": {
      "window_display": false,
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "library": "var_list.py",
          "delete_cmd_prefix": "del ",
          "delete_cmd_postfix": "",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "library": "var_list.r",
          "delete_cmd_prefix": "rm(",
          "delete_cmd_postfix": ") ",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ]
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "base_numbering": 1,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}